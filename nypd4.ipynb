{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction ###\n",
    "Prediction Problem: \n",
    "Given the NYPD DataFrame, classify whether or not the number of\n",
    "months elapsed for a complaint was greater than or equal to or less than the median number\n",
    "of months elapsed for every complaint.\n",
    "\n",
    "Since it is attempting to label each complaint in the DataFrame as either True or False, it is a\n",
    "classification problem.\n",
    "\n",
    "Within the DataFrame, there is a column named \"is_median\". Within this column, it labels as\n",
    "True or False whether or not the specific complaint took greater than or equal to or less than\n",
    "the median number of months elapsed for every complaint. For this classification problem,\n",
    "the model is attempting to correctly classify each complaint based on a set of features, and\n",
    "its correctness is based on this column, or target variable. The model used for this was a\n",
    "Decision Tree Classifier.\n",
    "\n",
    "For the evaluation metric, the model uses R-Squared to gauge the accuracy of our prediction\n",
    "because this is a classification problem.\n",
    "\n",
    "\n",
    "### Baseline Model ###\n",
    "\n",
    "For the baseline model, it uses 16 columns: 1. Numbers of Quantitative Columns: 3 2.\n",
    "Number of Ordinal Columns: 2 3. Number of Nominal Columns: 11\n",
    "\n",
    "Evaluation Metric:\n",
    "1. Training Data: 0.7842353505476057\n",
    "2. Testing Data: 0.7630695443645084\n",
    "\n",
    "In this case, it seems like the baseline model is decent, with a 75% accuracy on the test\n",
    "data.\n",
    "\n",
    "However, the model has a slightly higher R-Squared value for the training data compared to\n",
    "the R-Squared value of the testing data. Therefore, it seems that the baseline model is\n",
    "overfitting the training data. The max depth of the Decision tree was modified to have a\n",
    "balance between the accuracy of the testing prediction and the amount of overfit. It was\n",
    "found that a max depth of 10 provided the best results.\n",
    "\n",
    "Consequently, the baseline model is not a good model because it overfits the training data.\n",
    "\n",
    "\n",
    "### Final Model ###\n",
    "\n",
    "Engineered Features:\n",
    "1. The first engineered feature is a very simple feature that multiplies the month with the\n",
    "year. Since the model is attempting to classify whether or not a specific complaint took\n",
    "greater than or equal to or less than the median number of months elapsed for every\n",
    "complaint, these dates along with some combination of these dates will provide a lot of\n",
    "information for this model such that it is able to make more accurate classifications.\n",
    "\n",
    "2. Year Elapsed. This was found by finding the difference between year closed and year\n",
    "received\n",
    "\n",
    "3. [('complainant_age_incident', 'precinct'), ('year_received', 'mos_age_incident'),\n",
    "('year_closed', 'mos_age_incident'), ('month_received', 'mos_age_incident'),\n",
    "('month_closed', 'precinct'), ('month_closed', 'mos_age_incident'), ('mos_age_incident',\n",
    "'complainant_age_incident'), ('month_closed', 'complainant_age_incident'),\n",
    "('year_closed', 'precinct'), ('mos_age_incident', 'precinct'), ('year_received', 'precinct'),\n",
    "('month_received', 'complainant_age_incident'), ('month_received', 'precinct'),\n",
    "('year_received', 'complainant_age_incident'), ('year_closed',\n",
    "'complainant_age_incident')]. For each of these possible combinations, their linear\n",
    "regression score is added to a dictionary in order to check how well each pair predicts\n",
    "the target variable: \"is_median\". From here, these values are sorted by their score from\n",
    "best to worst. The best scores that do not include both the \"month_...\" and \"year_...”\n",
    "were included in the model by multiplying the pair of columns together such that it\n",
    "engineers a new feature.\n",
    "\n",
    "We also attempted to use Linear Regression by predicting the number of months that a\n",
    "particular complaint took, and using this value, we checked whether or not it took greater\n",
    "than or equal to or less than the median number of months elapsed for every complaint to\n",
    "classify that complaint as True or False. However, this model provided very horrible results\n",
    "with the R^2 being in the range of .1 to .2. Therefore, we decided to drop this idea\n",
    "completely and stick with either a Decision Tree Classifier or k-Means Clustering. Because\n",
    "this is a classification problem that classifies complaints as either True or False, it was\n",
    "between a Decision Tree Classifier and k-Means Clustering. We decided against using\n",
    "k-Means Clustering as the model because k-Means Clustering is often not as good for a\n",
    "higher dimensional set of features. Since the model used quite a large number of features,\n",
    "we decided against going for a k-Means Clustering Model, and we decided to stick with a\n",
    "Decision Tree Classifier. For this Decision Tree Classifier, the parameter that is taken into consideration is the max depth of the tree. In this case, the max depth was set to 10, which\n",
    "was the same as the max depth for the baseline model. This was intentional because we\n",
    "were attempting to check whether or not the engineered features would lead to a higher\n",
    "R-Squared value under this same constant, which would lead to a more fair evaluation of\n",
    "whether or not the engineered features provide for a higher correct classification rate and\n",
    "lower amount of overfitting.\n",
    "\n",
    "\n",
    "### Fairness Evaluation ###\n",
    "Question: \n",
    "Are the R^2 scores similar between male and female complainants?\n",
    "Null: The distribution of R^2 scores between male and female complainants are the same.\n",
    "Alternative: The distribution of R^2 scores between male and female complainants are not\n",
    "the same.\n",
    "\n",
    "Significance Threshold: .05\n",
    "\n",
    "Test Statistic: Difference in Accuracy\n",
    "\n",
    "For this evaluation we chose to use Accuracy over alternatives such as Recall or Precision.\n",
    "Since our prediction deals with a more general classification (true or false) the fairness metric\n",
    "of accuracy would be a better fit than alternatives such as precision. Due to it being binary,\n",
    "precision would not be as good of a metric due to it evaluating how precise, or how close\n",
    "predictions are to each other. Accuracy on the other hand will evaluate whether or not the\n",
    "correct prediction was made. After conducting the fairness evaluation, it was found that the\n",
    "p-value was 0.25. Since this is greater than the significance threshold of .05, we would reject\n",
    "the null hypothesis in favor of the alternative. This suggests that the accuracy for male and\n",
    "female complainants’ predictions are not the same. This could be because there are more\n",
    "male entries than female entries, so the data fit more in favor of the majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn import metrics \n",
    "from itertools import combinations\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # Higher resolution figures\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV File as DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_mos_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>command_now</th>\n",
       "      <th>shield_no</th>\n",
       "      <th>complaint_id</th>\n",
       "      <th>month_received</th>\n",
       "      <th>year_received</th>\n",
       "      <th>month_closed</th>\n",
       "      <th>year_closed</th>\n",
       "      <th>...</th>\n",
       "      <th>mos_age_incident</th>\n",
       "      <th>complainant_ethnicity</th>\n",
       "      <th>complainant_gender</th>\n",
       "      <th>complainant_age_incident</th>\n",
       "      <th>fado_type</th>\n",
       "      <th>allegation</th>\n",
       "      <th>precinct</th>\n",
       "      <th>contact_reason</th>\n",
       "      <th>outcome_description</th>\n",
       "      <th>board_disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004</td>\n",
       "      <td>Jonathan</td>\n",
       "      <td>Ruiz</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>8409</td>\n",
       "      <td>42835</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "      <td>Failure to provide RTKA card</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Report-domestic dispute</td>\n",
       "      <td>No arrest made or summons issued</td>\n",
       "      <td>Substantiated (Command Lvl Instructions)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10007</td>\n",
       "      <td>John</td>\n",
       "      <td>Sears</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>5952</td>\n",
       "      <td>24601</td>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Discourtesy</td>\n",
       "      <td>Action</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Moving violation</td>\n",
       "      <td>Moving violation summons issued</td>\n",
       "      <td>Substantiated (Charges)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10007</td>\n",
       "      <td>John</td>\n",
       "      <td>Sears</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>5952</td>\n",
       "      <td>24601</td>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Offensive Language</td>\n",
       "      <td>Race</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Moving violation</td>\n",
       "      <td>Moving violation summons issued</td>\n",
       "      <td>Substantiated (Charges)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10007</td>\n",
       "      <td>John</td>\n",
       "      <td>Sears</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>5952</td>\n",
       "      <td>26146</td>\n",
       "      <td>7</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "      <td>Question</td>\n",
       "      <td>67.0</td>\n",
       "      <td>PD suspected C/V of violation/crime - street</td>\n",
       "      <td>No arrest made or summons issued</td>\n",
       "      <td>Substantiated (Charges)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10009</td>\n",
       "      <td>Noemi</td>\n",
       "      <td>Sierra</td>\n",
       "      <td>078 PCT</td>\n",
       "      <td>24058</td>\n",
       "      <td>40253</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Force</td>\n",
       "      <td>Physical force</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Report-dispute</td>\n",
       "      <td>Arrest - other violation/crime</td>\n",
       "      <td>Substantiated (Command Discipline A)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_mos_id first_name last_name command_now  shield_no  complaint_id  \\\n",
       "0          10004   Jonathan      Ruiz     078 PCT       8409         42835   \n",
       "1          10007       John     Sears     078 PCT       5952         24601   \n",
       "2          10007       John     Sears     078 PCT       5952         24601   \n",
       "3          10007       John     Sears     078 PCT       5952         26146   \n",
       "4          10009      Noemi    Sierra     078 PCT      24058         40253   \n",
       "\n",
       "   month_received  year_received  month_closed  year_closed  ...  \\\n",
       "0               7           2019             5         2020  ...   \n",
       "1              11           2011             8         2012  ...   \n",
       "2              11           2011             8         2012  ...   \n",
       "3               7           2012             9         2013  ...   \n",
       "4               8           2018             2         2019  ...   \n",
       "\n",
       "  mos_age_incident complainant_ethnicity complainant_gender  \\\n",
       "0               32                 Black             Female   \n",
       "1               24                 Black               Male   \n",
       "2               24                 Black               Male   \n",
       "3               25                 Black               Male   \n",
       "4               39                   NaN                NaN   \n",
       "\n",
       "  complainant_age_incident           fado_type                    allegation  \\\n",
       "0                     38.0  Abuse of Authority  Failure to provide RTKA card   \n",
       "1                     26.0         Discourtesy                        Action   \n",
       "2                     26.0  Offensive Language                          Race   \n",
       "3                     45.0  Abuse of Authority                      Question   \n",
       "4                     16.0               Force                Physical force   \n",
       "\n",
       "  precinct                                contact_reason  \\\n",
       "0     78.0                       Report-domestic dispute   \n",
       "1     67.0                              Moving violation   \n",
       "2     67.0                              Moving violation   \n",
       "3     67.0  PD suspected C/V of violation/crime - street   \n",
       "4     67.0                                Report-dispute   \n",
       "\n",
       "                outcome_description                         board_disposition  \n",
       "0  No arrest made or summons issued  Substantiated (Command Lvl Instructions)  \n",
       "1   Moving violation summons issued                   Substantiated (Charges)  \n",
       "2   Moving violation summons issued                   Substantiated (Charges)  \n",
       "3  No arrest made or summons issued                   Substantiated (Charges)  \n",
       "4    Arrest - other violation/crime      Substantiated (Command Discipline A)  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read CSV File #\n",
    "csv_file = os.path.join('data', 'allegations.csv')\n",
    "\n",
    "# Read CSV File as DataFrame #\n",
    "nypd_df = pd.read_csv(csv_file)\n",
    "\n",
    "display(\n",
    "    nypd_df.head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA: Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unique_mos_id', 'first_name', 'last_name', 'command_now', 'shield_no',\n",
       "       'complaint_id', 'month_received', 'year_received', 'month_closed',\n",
       "       'year_closed', 'command_at_incident', 'rank_abbrev_incident',\n",
       "       'rank_abbrev_now', 'rank_now', 'rank_incident', 'mos_ethnicity',\n",
       "       'mos_gender', 'mos_age_incident', 'complainant_ethnicity',\n",
       "       'complainant_gender', 'complainant_age_incident', 'fado_type',\n",
       "       'allegation', 'precinct', 'contact_reason', 'outcome_description',\n",
       "       'board_disposition'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Columns #\n",
    "col_arr = nypd_df.columns\n",
    "\n",
    "display(\n",
    "    col_arr\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dropped redundant columns (rank_abbrev_incident, rank_abbrev_now) since there is another column in the dataframe that has the same information, except in a different format.\n",
    "Columns that contain information that would not be useful towards out prediction, like names or identification numbers, were also dropped in order to reduce noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['command_now', 'month_received', 'year_received', 'month_closed',\n",
       "       'year_closed', 'command_at_incident', 'rank_now', 'rank_incident',\n",
       "       'mos_ethnicity', 'mos_gender', 'mos_age_incident',\n",
       "       'complainant_ethnicity', 'complainant_gender',\n",
       "       'complainant_age_incident', 'fado_type', 'allegation', 'precinct',\n",
       "       'contact_reason', 'outcome_description', 'board_disposition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop: Redundant Columns #\n",
    "drop_col = [\n",
    "    'rank_abbrev_incident',\n",
    "    'rank_abbrev_now'\n",
    "]\n",
    "\n",
    "nypd_df = nypd_df.drop(drop_col, axis = 1)\n",
    "\n",
    "# Drop Unique ID Columns #\n",
    "drop_col = [\n",
    "    'unique_mos_id',\n",
    "    'first_name',\n",
    "    'last_name',\n",
    "    'shield_no',\n",
    "    'complaint_id',\n",
    "]\n",
    "\n",
    "nypd_df = nypd_df.drop(drop_col, axis = 1)\n",
    "\n",
    "nypd_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate: Month Elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses the datetime package to calculate the different in time, in terms of month. This information will be what we are trying to predict from the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_func(lst):\n",
    "    \n",
    "    date_frmt = '%Y-%m'\n",
    "    \n",
    "    start = datetime.datetime.strptime(lst[0], date_frmt)\n",
    "    end = datetime.datetime.strptime(lst[1], date_frmt)\n",
    "    calc_diff = relativedelta(end, start)\n",
    "    \n",
    "    num_mth = (calc_diff.years * 12) + calc_diff.months\n",
    "    \n",
    "    return num_mth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses the helper above on the nypd_df to get the month elasped between the received and closed date for each case. This it put into a new column called 'month_elapsed'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_time_elapsed(mth_r, yr_r, mth_c, yr_c):\n",
    "    \n",
    "    start_date = (\n",
    "        nypd_df[yr_r].astype(str) + '-' + nypd_df[mth_r].astype(str)\n",
    "    )\n",
    "    \n",
    "    end_date = (\n",
    "        nypd_df[yr_c].astype(str) + '-' + nypd_df[mth_c].astype(str)\n",
    "    )\n",
    "    \n",
    "    lambda_splt = lambda val: val.split()\n",
    "    comb_date = (start_date + ' ' + end_date).apply(lambda_splt)\n",
    "    time_elapsed = comb_date.apply(helper_func)\n",
    "        \n",
    "    return time_elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns 'month_elapsed' and 'is_median' are added to the dataframe. 'is_median' is a binary column which is True for when the month elapsed is greater than the median for all months elapsed and False otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median: 10.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_elapsed</th>\n",
       "      <th>is_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33353</th>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33354</th>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33355</th>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33356</th>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33357</th>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33358 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       month_elapsed  is_median\n",
       "0                 10       True\n",
       "1                  9      False\n",
       "2                  9      False\n",
       "3                 14       True\n",
       "4                  6      False\n",
       "...              ...        ...\n",
       "33353              6      False\n",
       "33354              6      False\n",
       "33355              6      False\n",
       "33356              6      False\n",
       "33357              6      False\n",
       "\n",
       "[33358 rows x 2 columns]"
      ]
     },
     "execution_count": 1127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nypd_df['month_elapsed'] = calc_time_elapsed('month_received', 'year_received', 'month_closed', 'year_closed')\n",
    "elapsed_median = nypd_df['month_elapsed'].median()\n",
    "nypd_df['is_median'] = nypd_df['month_elapsed'] >= elapsed_median\n",
    "\n",
    "\n",
    "print('Median:', elapsed_median)\n",
    "nypd_df[['month_elapsed', 'is_median']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This baseline model imputes the missing values with 0's and nulls for numerical and categorical variables respectively. It also ordinal encodes the rank columns and one hot encodes the categorical columns. Since this is a classification problem, a decision tree was used with max depth as 10, which was found to reduce the models overfit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nypd_df.drop(['is_median', 'month_elapsed'], axis=1)\n",
    "y = nypd_df['is_median']\n",
    "\n",
    "# Gets a list of categorial columns and a list of numerical columns\n",
    "types = X.dtypes\n",
    "catcols = types.loc[types == np.object].index\n",
    "numcols = types.loc[types != np.object].index\n",
    "\n",
    "num_cols = [\n",
    "    'month_received',\n",
    "    'year_received',\n",
    "    'complainant_age_incident',\n",
    "]\n",
    "\n",
    "# These two columns are ordinally encoded\n",
    "ord_col = [\n",
    "    'rank_incident',\n",
    "    'rank_now'\n",
    "]\n",
    "ords = Pipeline(\n",
    "    steps = [\n",
    "        ('ordinal_encoding', OrdinalEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Every other categorical column that is not ordinal is considered nominal. These are imputed and one hot encoded.\n",
    "nom_col = [col for col in catcols if (col not in ord_col)]\n",
    "nom = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='constant', fill_value='NULL')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('nomcols', nom, catcols),\n",
    "    ('numcols', SimpleImputer(strategy='constant', fill_value=0), num_cols),\n",
    "    ('ordcols', ords, ord_col)\n",
    "])\n",
    "\n",
    "pl = Pipeline([('feats', ct), ('reg', DecisionTreeClassifier(max_depth=10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('feats',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('nomcols',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imp',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value='NULL',\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='constant',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(categories='auto',\n",
       "                                                                                 drop=Non...\n",
       "                                                   'rank_now'])],\n",
       "                                   verbose=False)),\n",
       "                ('reg',\n",
       "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                        criterion='gini', max_depth=10,\n",
       "                                        max_features=None, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort='deprecated', random_state=None,\n",
       "                                        splitter='best'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 1129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R^2 for the training model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7859940842593333"
      ]
     },
     "execution_count": 1130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.score(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R^2 for the test model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.752757793764988"
      ]
     },
     "execution_count": 1131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column 'month_x_year' is the produce of month received and year received. Since those two are strong predictors for the is_median columns, engineering a feature out of them may bring up the accuracy of the model. Another column called 'year_elapsed' was created by finding the difference between the year closed and year received for each case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "metadata": {},
   "outputs": [],
   "source": [
    "nypd_df['month_x_year'] = nypd_df.month_received * nypd_df.year_received\n",
    "nypd_df['year_elapsed'] = nypd_df['year_closed'] - nypd_df['year_received']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of numerical columns in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['month_received', 'year_received', 'month_closed', 'year_closed',\n",
       "       'mos_age_incident', 'complainant_age_incident', 'precinct'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numcols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts the column we want to predict to a column of 1's and 0's to be used for manual iterative method to find the best feature pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_received</th>\n",
       "      <th>year_received</th>\n",
       "      <th>month_closed</th>\n",
       "      <th>year_closed</th>\n",
       "      <th>mos_age_incident</th>\n",
       "      <th>complainant_age_incident</th>\n",
       "      <th>precinct</th>\n",
       "      <th>is_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>32</td>\n",
       "      <td>38.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>24</td>\n",
       "      <td>26.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "      <td>24</td>\n",
       "      <td>26.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "      <td>25</td>\n",
       "      <td>45.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>39</td>\n",
       "      <td>16.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_received  year_received  month_closed  year_closed  mos_age_incident  \\\n",
       "0               7           2019             5         2020                32   \n",
       "1              11           2011             8         2012                24   \n",
       "2              11           2011             8         2012                24   \n",
       "3               7           2012             9         2013                25   \n",
       "4               8           2018             2         2019                39   \n",
       "\n",
       "   complainant_age_incident  precinct  is_median  \n",
       "0                      38.0      78.0          1  \n",
       "1                      26.0      67.0          0  \n",
       "2                      26.0      67.0          0  \n",
       "3                      45.0      67.0          1  \n",
       "4                      16.0      67.0          0  "
      ]
     },
     "execution_count": 1134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nypd_num = nypd_df[numcols]\n",
    "nypd_num['is_median'] = nypd_df['is_median'].astype(int)\n",
    "nypd_num = nypd_num.dropna().reset_index(drop=True)\n",
    "nypd_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code initializes a new model and finds every possible combinations for the columns within the numerical subset dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_comb = nypd_num.drop('is_median', axis = 1)\n",
    "y_train = nypd_num['is_median']\n",
    "\n",
    "col_list = X_comb.columns\n",
    "combos = list(combinations(col_list, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the possible combinations, its linear regression score is added to a dictionary to see how well each pair predicts 'is_median'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds the score for each pair of features using linear regression\n",
    "\n",
    "dic = {}\n",
    "for combo in combos:\n",
    "   X_train_int = X_comb\n",
    "   X_train_int['int'] = X_train_int[combo[0]] * X_train_int[combo[1]]\n",
    "   lr = LinearRegression()\n",
    "   lr.fit(X_train_int, y_train)\n",
    "   scored = lr.score(X_train_int, y_train)\n",
    "   dic[scored] = combo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These R^2 scores are then sorted in decreasing order to see which pairs best predict is_median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('month_received', 'month_closed') R2: 0.6660351700572122\n",
      "('year_received', 'month_closed') R2: 0.6278377634264865\n",
      "('year_received', 'year_closed') R2: 0.6278205331302502\n",
      "('complainant_age_incident', 'precinct') R2: 0.6277753999928355\n",
      "('year_received', 'mos_age_incident') R2: 0.6277514818168362\n",
      "('year_closed', 'mos_age_incident') R2: 0.6277316600071761\n",
      "('month_received', 'mos_age_incident') R2: 0.6277096871993945\n",
      "('month_received', 'year_closed') R2: 0.6276980495448005\n",
      "('month_closed', 'precinct') R2: 0.6276819875105961\n",
      "('month_closed', 'mos_age_incident') R2: 0.6276705546879111\n",
      "('mos_age_incident', 'complainant_age_incident') R2: 0.6276639425757718\n",
      "('month_closed', 'complainant_age_incident') R2: 0.6276533843430219\n",
      "('year_closed', 'precinct') R2: 0.6276530733860418\n",
      "('mos_age_incident', 'precinct') R2: 0.6276495737557267\n",
      "('year_received', 'precinct') R2: 0.6276438167693917\n",
      "('month_received', 'complainant_age_incident') R2: 0.6276437928202467\n",
      "('month_received', 'year_received') R2: 0.6276386152553217\n",
      "('month_received', 'precinct') R2: 0.6276384937093864\n",
      "('year_received', 'complainant_age_incident') R2: 0.6276326330596222\n",
      "('year_closed', 'complainant_age_incident') R2: 0.6276320772949907\n"
     ]
    }
   ],
   "source": [
    "best = sorted(dic.keys(), reverse = True)[:20]\n",
    "counter = 0\n",
    "best_combos = []\n",
    "for combo in best:\n",
    "   best_combos.append(dic[combo])\n",
    "   print(dic[combo], 'R2:', best[counter])\n",
    "   counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns that do not have both year and month attributes are then filtered to be used in the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('complainant_age_incident', 'precinct'),\n",
       " ('year_received', 'mos_age_incident'),\n",
       " ('year_closed', 'mos_age_incident'),\n",
       " ('month_received', 'mos_age_incident'),\n",
       " ('month_closed', 'precinct'),\n",
       " ('month_closed', 'mos_age_incident'),\n",
       " ('mos_age_incident', 'complainant_age_incident'),\n",
       " ('month_closed', 'complainant_age_incident'),\n",
       " ('year_closed', 'precinct'),\n",
       " ('mos_age_incident', 'precinct'),\n",
       " ('year_received', 'precinct'),\n",
       " ('month_received', 'complainant_age_incident'),\n",
       " ('month_received', 'precinct'),\n",
       " ('year_received', 'complainant_age_incident'),\n",
       " ('year_closed', 'complainant_age_incident')]"
      ]
     },
     "execution_count": 1138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_combos = []\n",
    "reqs = ['month_received', 'month_closed', 'year_elapsed', 'year_closed', 'month_year', 'year_received']\n",
    "for i in best_combos:\n",
    "    if i[0] not in reqs or i[1] not in reqs:\n",
    "        filtered_combos.append(i)\n",
    "filtered_combos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of columns before and after this feature engineering. A total of 15 new columns were added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (33358, 24)\n",
      "After: (33358, 39)\n",
      "Num Columns Added: 15\n"
     ]
    }
   ],
   "source": [
    "prev_shape = nypd_df.shape\n",
    "for i in filtered_combos:\n",
    "    new_col = nypd_df[i[0]] * nypd_df[i[1]]\n",
    "    nypd_df[i] = new_col\n",
    "\n",
    "print('Before:', prev_shape)\n",
    "print('After:', nypd_df.shape)\n",
    "print('Num Columns Added:', nypd_df.shape[1] - prev_shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to what was done in the baseline model, the final model included the new engineer columns, binarized columns of if at least 2 years elapsed or not, numerical columns imputed with the mean instead of 0, and PCA done on the allegations columns to reduce noise since that column consisted of many unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nypd_df.drop(['is_median', 'month_elapsed'], axis=1)\n",
    "y = nypd_df['is_median']\n",
    "\n",
    "types = X.dtypes\n",
    "catcols = types.loc[types == np.object].index\n",
    "numcols = types.loc[types != np.object].index\n",
    "\n",
    "num_cols = [\n",
    "    'month_received',\n",
    "    'year_received',\n",
    "    'complainant_age_incident',\n",
    "    'month_x_year'\n",
    "] + filtered_combos    #includes the new feature pair columns that were engineered\n",
    "\n",
    "bin_col = [\n",
    "    'year_elapsed'\n",
    "]\n",
    "# binarizes the year elapsed column to True if at least 2 years have passed and False otherwise\n",
    "bin_transf = Pipeline(\n",
    "    steps = [\n",
    "        ('binarizer', Binarizer(threshold = 2))\n",
    "    ])\n",
    "\n",
    "# ordinally encodes these two columns\n",
    "ord_col = [\n",
    "    'rank_incident',\n",
    "    'rank_now'\n",
    "]\n",
    "ords = Pipeline(\n",
    "    steps = [\n",
    "        ('ordinal_encoding', OrdinalEncoder(handle_unknown='ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "dont_include = ['rank_now', 'command_now', 'allegation']\n",
    "# everything besides what was already engineered is considered as nominal\n",
    "nom_col = [col for col in catcols if (col not in ord_col)]\n",
    "nom_col = [col for col in catcols if (col not in dont_include)]\n",
    "nom = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='constant', fill_value='NULL')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "alleg = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='constant', fill_value='NULL')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
    "    ('pca', PCA(svd_solver='auto', n_components=50))\n",
    "])\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('catcols', nom, catcols),\n",
    "    ('numcols', SimpleImputer(strategy='mean'), num_cols),\n",
    "    ('ordcols', ords, ord_col),\n",
    "    ('alleg', alleg, ['allegation']),\n",
    "    ('bina', bin_transf, bin_col)\n",
    "])\n",
    "\n",
    "pl = Pipeline([('feats', ct), ('reg', DecisionTreeClassifier(max_depth=10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('feats',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('catcols',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imp',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value='NULL',\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='constant',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(categories='auto',\n",
       "                                                                                 drop=Non...\n",
       "                                                  ['year_elapsed'])],\n",
       "                                   verbose=False)),\n",
       "                ('reg',\n",
       "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                        criterion='gini', max_depth=10,\n",
       "                                        max_features=None, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort='deprecated', random_state=None,\n",
       "                                        splitter='best'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 1141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training score for final model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8440322967463426"
      ]
     },
     "execution_count": 1142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test score for final model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8105515587529976"
      ]
     },
     "execution_count": 1143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Are the R^2 scores similar between male and female complainants?\n",
    "\n",
    "Null: The distribution of R^2 scores between male and female complainants are the same. \n",
    "\n",
    "Alternative: The distribution of R^2 scores between male and female complainants are not the same.\n",
    "\n",
    "Significance Threshold: .05\n",
    "\n",
    "Test Statistic: Difference in Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was taken from project 3 to clean the complainant gender column. It converts the genders to only male and female for the purposes of our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Column: 'complainant_gender' #\n",
    "\n",
    "# 'Transman (FTM)' = 'Male' #\n",
    "nypd_df['complainant_gender'] = (nypd_df\n",
    "    ['complainant_gender']\n",
    "    .replace('Transman (FTM)', 'Male')\n",
    ")\n",
    "\n",
    "# 'Transwoman (MTF)' = 'Female' #\n",
    "nypd_df['complainant_gender'] = (nypd_df\n",
    "    ['complainant_gender']\n",
    "    .replace('Transwoman (MTF)', 'Female')\n",
    ")\n",
    "\n",
    "# 'Not described' = NaN #\n",
    "nypd_df['complainant_gender'] = (nypd_df\n",
    "    ['complainant_gender']\n",
    "    .replace('Not described', np.NaN)\n",
    ")\n",
    "\n",
    "# Drop 'Gender non-conforming' #\n",
    "nypd_subset = nypd_df[\n",
    "    (nypd_df['complainant_gender'] == 'Male') \n",
    "        |\n",
    "    (nypd_df['complainant_gender'] == 'Female')\n",
    "        |\n",
    "    (nypd_df['complainant_gender'].isnull())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper function to create subsets of a given dataframe, one with males and one with females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def male_female_split(df):\n",
    "    col = 'complainant_gender'\n",
    "    male = df[df[col] == 'Male']\n",
    "    female = df[df[col] == 'Female']\n",
    "    return male, female\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper method to calculate the precision of a given dataset. It creates a pipeline similar to the final model's then calculates the precision of that pipeline. It is a slightly modified version of the code to construct the final pipeline above. In addition to creating the pipeline, it also calculates the precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_calc(df):\n",
    "    X = nypd_df.drop(['is_median', 'month_elapsed'], axis=1)\n",
    "    y = nypd_df['is_median']\n",
    "\n",
    "    types = X.dtypes\n",
    "    catcols = types.loc[types == np.object].index\n",
    "    numcols = types.loc[types != np.object].index\n",
    "\n",
    "    num_cols = [\n",
    "        'month_received',\n",
    "        'year_received',\n",
    "        'complainant_age_incident',\n",
    "        'month_x_year'\n",
    "    ] + filtered_combos    #includes the new feature pair columns that were engineered\n",
    "\n",
    "    bin_col = [\n",
    "        'year_elapsed'\n",
    "    ]\n",
    "    bin_transf = Pipeline(\n",
    "        steps = [\n",
    "            ('binarizer', Binarizer(threshold = 2))\n",
    "        ])\n",
    "\n",
    "    ord_col = [\n",
    "        'rank_incident',\n",
    "        'rank_now'\n",
    "    ]\n",
    "    ords = Pipeline(\n",
    "        steps = [\n",
    "            ('ordinal_encoding', OrdinalEncoder())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    dont_include = ['rank_now', 'command_now', 'allegation']\n",
    "    cat_col = [col for col in catcols if (col not in ord_col)]\n",
    "    cat_col = [col for col in catcols if (col not in dont_include)]\n",
    "    cats = Pipeline([\n",
    "        ('imp', SimpleImputer(strategy='constant', fill_value='NULL')),\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    ])\n",
    "\n",
    "    alleg = Pipeline([\n",
    "        ('imp', SimpleImputer(strategy='constant', fill_value='NULL')),\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
    "        ('pca', PCA(svd_solver='auto', n_components=50))\n",
    "    ])\n",
    "\n",
    "    ct = ColumnTransformer([\n",
    "        ('catcols', cats, catcols),\n",
    "        ('numcols', SimpleImputer(strategy='mean'), num_cols),\n",
    "        ('ordcols', ords, ord_col),\n",
    "        ('alleg', alleg, ['allegation']),\n",
    "        ('bina', bin_transf, bin_col)\n",
    "    ])\n",
    "\n",
    "    pl = Pipeline([('feats', ct), ('reg', DecisionTreeClassifier(max_depth=10))])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    pl.fit(X_train, y_train)\n",
    "    preds = pl.predict(X_test)\n",
    "    \n",
    "    metrics.accuracy_score(y_test, preds)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, preds).ravel()\n",
    "    precision = (tp + tn) / (tp + fn + tn + fp)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper method to calculate the observed precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_acc(df):\n",
    "    male, female = male_female_split(nypd_df)\n",
    "\n",
    "    m_prec = accuracy_calc(male)\n",
    "    f_prec = accuracy_calc(female)\n",
    "\n",
    "    difference = np.abs(m_prec - f_prec)\n",
    "    return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = obs_acc(nypd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code conducts a permutation test with the difference of precision as the test statistic. It calculates the R^2 for each male and female rows then find the difference between those two and adds it to a list. At the ends, the p-value is calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.8\n"
     ]
    }
   ],
   "source": [
    "n_repetitions = 100\n",
    "\n",
    "differences = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # shuffle the weights\n",
    "    shuffled_gender = (\n",
    "        nypd_df['complainant_gender']\n",
    "        .sample(replace=False, frac=1)\n",
    "        .reset_index(drop=True) \n",
    "    )\n",
    "    \n",
    "    # put them in a table\n",
    "    shuffled = (\n",
    "        nypd_df\n",
    "        .assign(**{'complainant_gender': shuffled_gender})\n",
    "    )\n",
    "    \n",
    "    # split the dataframe into male and female \n",
    "    male, female = male_female_split(nypd_df)\n",
    "\n",
    "    # calculate the precision for male and female subset datasets\n",
    "    m_prec = accuracy_calc(male)\n",
    "    f_prec = accuracy_calc(female)\n",
    "\n",
    "    difference = np.abs(m_prec - f_prec)\n",
    "    \n",
    "    # add it to the list of results\n",
    "    differences.append(difference)\n",
    "\n",
    "p_val = np.count_nonzero(differences >= obs) / n_repetitions\n",
    "print('p-value:', p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
